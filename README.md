# PPO-algorithm-post-train-LLM-7B
## 本项目的基本思路
Trained with the PPO algorithm, quantized and fine-tuned with Lora, the 7B large model can run on lightweight cloud servers
本项目基于RL对LLM-7B的模型进行post-train以实现LLM-7B可以自主的玩zork游戏，在我们的训练过程我们才用了LL
